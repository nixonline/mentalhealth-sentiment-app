{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this project is a curated collection of mental health statements compiled from various sources by Kaggle user Suchintika Sarkar.\n",
    "\n",
    "Kaggle version of the dataset:\n",
    "https://www.kaggle.com/datasets/suchintikasarkar/sentiment-analysis-for-mental-health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26hOX3ckUWk0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import kagglehub\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer, EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qD3eoR__T-sc",
    "outputId": "3e281450-5d39-4533-fbc1-fb345860863a"
   },
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"suchintikasarkar/sentiment-analysis-for-mental-health\")\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "AVMYNSlNUD2Y",
    "outputId": "ea5ced87-1b26-49f9-a9fa-7f24aa487fbf"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_files[0])\n",
    "df = df[['statement', 'status']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row Count and Nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has already been cleaned, but rows with null statements should be dropped to prevent errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwcQ3Qu3WpQx"
   },
   "outputs": [],
   "source": [
    "row_count = df.shape[0]\n",
    "df = df.dropna(subset=['statement'])\n",
    "new_row_count = df.shape[0]\n",
    "\n",
    "print(f\"Row count before cleaning: {row_count}\\nRow count after dropping null statement: {new_row_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "SVrwUGh4UdjM",
    "outputId": "59260b77-defe-4f48-8e9e-0af491ede90a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(data=df, x='status')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top two categories contain significantly more samples than the others, which may affect predictive performance across all classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = 300  # or 500\n",
    "df['text_length'] = df['statement'].apply(lambda x: len(x.split()))\n",
    "df['text_length_capped'] = df['text_length'].clip(upper=cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = df['text_length'].min()\n",
    "max_length = df['text_length'].max()\n",
    "median_length = df['text_length'].median()\n",
    "mean_length = df['text_length'].mean()\n",
    "\n",
    "# Display results\n",
    "print(f\"Minimum text length: {min_length} words\")\n",
    "print(f\"Maximum text length: {max_length} words\")\n",
    "print(f\"Median text length: {median_length} words\")\n",
    "print(f\"Average text length: {mean_length:.2f} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "-CPRHqtKWXp3",
    "outputId": "0e09cb65-18f8-40a4-91d3-44a65180b97d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df['text_length_capped'], bins=30)\n",
    "plt.title(f\"Text Length Distribution (Capped at {cap} words)\")\n",
    "plt.xlabel(\"Number of words\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of the samples have a word count below 25. A long-tail distribution is expected in open-text datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('status')['text_length'].agg(['min', 'max', 'median', 'mean']).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the stats:\n",
    "- Normal texts are shorter\n",
    "- Clinical categories are longer and variable\n",
    "- The signifficant difference in length suggests that struggling people tend to write more detailed statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "idW4h4h1WeJP",
    "outputId": "e0609ada-e14f-4138-9908-e6d31f884eeb"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['status'])\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to sample imbalance and varying word counts across categories, we will apply class weights to reduce bias toward the Normal category and strengthen representation of the smaller ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZ9mcqYBSBTi"
   },
   "outputs": [],
   "source": [
    "class_weight = {\n",
    "    0: 1.0,   # Anxiety\n",
    "    1: 1.0,   # Bipolar\n",
    "    2: 1.2,   # Depression\n",
    "    3: 0.6,   # Normal\n",
    "    4: 1.8,   # Personality disorder\n",
    "    5: 1.4,   # Stress\n",
    "    6: 1.5    # Suicidal\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_fX5lWW08YbM"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['statement'],\n",
    "    df['label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['label']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-p_v4RlY8d2f"
   },
   "outputs": [],
   "source": [
    "baseline_model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=30000,\n",
    "        ngram_range=(1,3),\n",
    "        min_df=3,\n",
    "        max_df=0.9,\n",
    "        sublinear_tf=True,\n",
    "        lowercase=True\n",
    "    )),\n",
    "    ('clf', LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        solver='lbfgs',\n",
    "        n_jobs=-1,\n",
    "        class_weight=class_weight\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyxww2G18fWC",
    "outputId": "7ab78a65-fcbc-420c-b0cd-ec3b5a792389"
   },
   "outputs": [],
   "source": [
    "baseline_model.fit(X_train, y_train)\n",
    "y_pred = baseline_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=range(len(le.classes_)))\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model struggles classifying between Depression and Suicidal, possibly due to overlapping language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256,
     "referenced_widgets": [
      "f34ae3a42d574795b872fb4da3192502",
      "21fdf167cd05437eaa9e8c0a40bfbd85",
      "c1040c44928e475d96e3e56422fe8448",
      "6584bc065b514491bc5d38e2a57dd3ee",
      "89effd3cf1bf4cb3957fceb8b6910a64",
      "d8e92c5e0a7e4715a57000fb7a6850ef",
      "a8ad0e47dd8b46409bf45f97be0626b7",
      "ded0da3307474a69954f16a73e98a4ad",
      "1fbb1767d6cb4cb48e31a2e9fd4458e4",
      "eb777c1ae67c4424a8b7ef05502f2ef6",
      "181b361832444108990f04cbfa7f115d",
      "e05d322f99bb4afa9781d8ccb9b9af47",
      "9ad779fa92a44ce988bcfef4e0adb821",
      "5011b361796248919201986e36225d31",
      "07920ab095e8420499f457a70cf5ccad",
      "caa7b83fdc7945c7997331e13a79ee3f",
      "34806e7f13a9430fbbe94b87194467bb",
      "294577a525e14f92b0676202f2dc5022",
      "e9e5322994c14fcd89d7d77ff05ff781",
      "33bc72c7554b46c383184d086f25002b",
      "d0d912ccbfac477995f2ec193fa9b4c5",
      "87dc850750874935b0c1c96963c944e7",
      "f31cad251bd0449db6ce4a397c811fc7",
      "db689dbcf53b441aa2a5b38bf6044e78",
      "ccfc31b2fd5f4afcab273128633ede1a",
      "2121c29b740d43bdaa2f11d39db017ce",
      "0ed6c182d8dd45fa85dad01c3bc17565",
      "8f8334136df64598aa223b99127e27e2",
      "9c9a0a107cc74fd3b6ee18cbc2981f27",
      "d9e9becf6c3f4d89bb19a5ced72252ee",
      "ec315d9579c14d6983a85a579d705884",
      "a5ee953631d646f2a60c7c625cf7bd22",
      "aa3041264c3a414887273c9e229752f4",
      "f9d784bf1ae94661a0b99bf8aed1dc86",
      "f5d7e642dd804fe2bd932c0798987ede",
      "ae2224e604f94d83a9dbcdf23721de14",
      "602972bdbe0a42a490d2671f592968eb",
      "26ada9c4c6f24e5199b9c00c4a8c1307",
      "ecd333cf5fc94b9caecb8304adc4e1f1",
      "b7b1c1a8f7794809b942f9bbe1f839e1",
      "e23af1d5c840414cb0871534db9192f5",
      "744d1a7f356745a6b69a6f8eeaa19f80",
      "b06906a6239243df8ece97065bd6295c",
      "31fc2e4d10b84ce5b948f2c0b3e80ec9"
     ]
    },
    "id": "99gSad9Y9L8P",
    "outputId": "728120e1-338b-4f60-f1c9-f2c54bbe00ee"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LgIfx3Ap9T6P"
   },
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch['statement'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "22acc22bb14f4aea97264ad5d1257625",
      "8c752177d1b448e2be5b09d9d34453b1",
      "18c48abc20e94de2b18d08824203f3e7",
      "32e27fe64e5b464697acd91dff948719",
      "4b95c4c3d7d54ce3ba11d236e63818de",
      "82f59a2058dc4ebd97fa0d57a13e99b4",
      "d756dfe10e6a4e9fa3bca8541dcc9e56",
      "037aa106be814d989325e3bd8bcc3e17",
      "557ca836eaec4368ac9c69ebaf30b442",
      "cdcf95fcdd3640e8b38b9136e84445e1",
      "58275de70b9d4355a9cfd7e2a36ea967",
      "f724c3613bd34fcfbabcb198c0107fc8",
      "35a3c6317f004900b8e579f3494a8b87",
      "f40823fef8a3438396c596b36b91a98e",
      "0ed3db64368c4533ac55d374b527f38f",
      "500ae2d9bd16440b8b0ba9ebb21b84d9",
      "d608c6f1751d401d9cf9f992b0ee6411",
      "a55dd6ca09564fb3b3a00f8324488172",
      "82bf01fe93c348caa570d2b03a78834f",
      "7f1f350b80ec463aa60085d3bf88e1b2",
      "2ba60801cf55476988381ad890116a0f",
      "2d61d9249d4e4bfe999ca6150eb7c1f3"
     ]
    },
    "id": "8q1PH0or9UPO",
    "outputId": "a63e2bbb-1e06-41c0-91da-1f9d9746f0ff"
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({'statement': X_train, 'label': y_train})\n",
    "test_df  = pd.DataFrame({'statement': X_test,  'label': y_test})\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds  = Dataset.from_pandas(test_df)\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "test_ds  = test_ds.map(tokenize, batched=True)\n",
    "\n",
    "train_ds = train_ds.remove_columns(['statement'])\n",
    "test_ds  = test_ds.remove_columns(['statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.set_format(\"torch\")\n",
    "test_ds.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUE6TsVw9rQe"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sf8yjmzR9sht",
    "outputId": "42a505c7-f77e-49a1-811d-bbd5e0d20c44"
   },
   "outputs": [],
   "source": [
    "model_path = \"model_state.pt\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"âœ… Found model_state.pt â€” loading weights...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\",\n",
    "        num_labels=num_classes\n",
    "    )\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "else:\n",
    "    print(\"ðŸš€ model_state.pt not found â€” training from scratch...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\",\n",
    "        num_labels=num_classes\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=test_ds,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UTJD1d_79vnu"
   },
   "outputs": [],
   "source": [
    "preds = trainer.predict(test_ds)\n",
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=range(len(le.classes_)))\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the overall performance improved, the newer model still struggles to classify between Depression and Suicidal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    \"text\": X_test,\n",
    "    \"true_label\": y_test,\n",
    "    \"pred_label\": y_pred\n",
    "})\n",
    "\n",
    "results_df[\"true_label_name\"] = le.inverse_transform(results_df[\"true_label\"])\n",
    "results_df[\"pred_label_name\"] = le.inverse_transform(results_df[\"pred_label\"])\n",
    "\n",
    "misclassified = results_df[results_df[\"true_label\"] != results_df[\"pred_label\"]]\n",
    "\n",
    "print(\"Number of misclassified samples:\", len(misclassified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondary Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the results, a new model will be trained to better distinguish Depression from Suicidal remarks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depr_code = le.transform([\"Depression\"])[0]\n",
    "suic_code = le.transform([\"Suicidal\"])[0]\n",
    "\n",
    "binary_df = df[df[\"label\"].isin([depr_code, suic_code])].copy()\n",
    "\n",
    "binary_df[\"binary_label\"] = binary_df[\"label\"].map({\n",
    "    depr_code: 0,   # Depression â†’ 0\n",
    "    suic_code: 1    # Suicidal â†’ 1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_bin, eval_df_bin = train_test_split(\n",
    "    binary_df[[\"statement\", \"binary_label\"]],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=binary_df[\"binary_label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train_ds = Dataset.from_pandas(train_df_bin)\n",
    "binary_eval_ds  = Dataset.from_pandas(eval_df_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train_ds = binary_train_ds.map(tokenize, batched=True)\n",
    "binary_eval_ds  = binary_eval_ds.map(tokenize, batched=True)\n",
    "\n",
    "binary_train_ds = binary_train_ds.rename_column(\"binary_label\", \"labels\")\n",
    "binary_eval_ds  = binary_eval_ds.rename_column(\"binary_label\", \"labels\")\n",
    "\n",
    "binary_train_ds = binary_train_ds.remove_columns([\"statement\"])\n",
    "binary_eval_ds  = binary_eval_ds.remove_columns([\"statement\"])\n",
    "\n",
    "binary_train_ds.set_format(\"torch\")\n",
    "binary_eval_ds.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_training_args = TrainingArguments(\n",
    "    output_dir=\"./binary_results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=\"./binary_logs\",\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model_path = \"binary_model_state.pt\"\n",
    "\n",
    "if os.path.exists(binary_model_path):\n",
    "    print(\"âœ… Found binary_model_state.pt â€” loading weights...\")\n",
    "    binary_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\",\n",
    "        num_labels=2\n",
    "    )\n",
    "    state_dict = torch.load(binary_model_path, map_location=device)\n",
    "    binary_model.load_state_dict(state_dict)\n",
    "else:\n",
    "    print(\"ðŸš€ binary_model_state.pt not found â€” training from scratch...\")\n",
    "    binary_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\",\n",
    "        num_labels=2\n",
    "    )\n",
    "\n",
    "    binary_trainer = Trainer(\n",
    "        model=binary_model,\n",
    "        args=binary_training_args,\n",
    "        train_dataset=binary_train_ds,\n",
    "        eval_dataset=binary_eval_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "    binary_trainer.train()\n",
    "\n",
    "    torch.save(binary_model.state_dict(), binary_model_path)\n",
    "\n",
    "binary_trainer = Trainer(\n",
    "    model=binary_model,\n",
    "    args=binary_training_args,\n",
    "    train_dataset=binary_train_ds,\n",
    "    eval_dataset=binary_eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = binary_trainer.predict(binary_eval_ds)\n",
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "\n",
    "y_true = np.array(binary_eval_ds[\"labels\"])\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Depression\", \"Suicidal\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Depression\", \"Suicidal\"],\n",
    "            yticklabels=[\"Depression\", \"Suicidal\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Binary Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merged Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Predict all class.\n",
    "2. Run all Depression/Suicidal predictions on the binary model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_preds = trainer.predict(test_ds)\n",
    "multiclass_labels = np.argmax(multiclass_preds.predictions, axis=1)\n",
    "\n",
    "depr_code = le.transform([\"Depression\"])[0]\n",
    "suic_code = le.transform([\"Suicidal\"])[0]\n",
    "target_codes = [depr_code, suic_code]\n",
    "\n",
    "refine_indices = [i for i, label in enumerate(multiclass_labels) if label in target_codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if refine_indices:\n",
    "    refine_texts = test_df.iloc[refine_indices][\"statement\"].tolist()\n",
    "    refine_encodings = tokenizer(refine_texts, truncation=True, padding=True)\n",
    "    refine_ds = Dataset.from_dict(refine_encodings)\n",
    "\n",
    "    binary_preds = binary_trainer.predict(refine_ds)\n",
    "    binary_labels = np.argmax(binary_preds.predictions, axis=1)\n",
    "\n",
    "    for j, idx in enumerate(refine_indices):\n",
    "        multiclass_labels[idx] = depr_code if binary_labels[j] == 0 else suic_code\n",
    "\n",
    "y_true = test_df[\"label\"].values\n",
    "\n",
    "print(classification_report(y_true, multiclass_labels, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, multiclass_labels, labels=range(len(le.classes_)))\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix (Cascade Model)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modelâ€™s overall performance increased by 10%, with a notable improvement in recall for the Suicidal class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Step Predictor Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(texts):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True)\n",
    "    ds = Dataset.from_dict(encodings)\n",
    "    preds = trainer.predict(ds)\n",
    "    multiclass_labels = preds.predictions.argmax(-1)\n",
    "\n",
    "    depr_code = le.transform([\"Depression\"])[0]\n",
    "    suic_code = le.transform([\"Suicidal\"])[0]\n",
    "    target_codes = [depr_code, suic_code]\n",
    "\n",
    "    refine_indices = [i for i, label in enumerate(multiclass_labels) if label in target_codes]\n",
    "\n",
    "    if refine_indices:\n",
    "        refine_texts = [texts[i] for i in refine_indices]\n",
    "        refine_encodings = tokenizer(refine_texts, truncation=True, padding=True)\n",
    "        refine_ds = Dataset.from_dict(refine_encodings)\n",
    "\n",
    "        binary_preds = binary_trainer.predict(refine_ds)\n",
    "        binary_labels = binary_preds.predictions.argmax(-1)\n",
    "\n",
    "        for j, idx in enumerate(refine_indices):\n",
    "            multiclass_labels[idx] = depr_code if binary_labels[j] == 0 else suic_code\n",
    "\n",
    "    return [le.classes_[i] for i in multiclass_labels]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNy0/oWaY0913pGDbJ/3SYJ",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
